{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4844905-faf8-4270-8240-cc931fda6acd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD16 Hands-On: Machine Learning Lifecycle mit MLflow\n",
    "**Szenario:** Wir sind Data Scientists bei einer Immobilienfirma. Unser Ziel ist es, ein KI-Modell zu trainieren, das basierend auf **Lage**, **Größe**, **Qualität** und **Baujahr** den Preis eines Hauses schätzt.\n",
    "\n",
    "**Der Ablauf:**\n",
    "1.  \uD83E\uDDEA **Training (Experiments):** Wir trainieren das Modell und tracken Metriken.\n",
    "2.  \uD83D\uDCDA **Registrierung (Models):** Wir speichern das beste Modell sauber ab.\n",
    "3.  \uD83D\uDD2E **Vorhersage (Inference):** Wir nutzen das Modell für neue Schätzungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41bfa646-dbc7-434c-89df-7b1225e019c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Erstelle Trainingstabelle workspace.default.house_prices...\n✅ Daten bereitgestellt.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Neighborhood</th><th>GrLivArea</th><th>OverallQual</th><th>YearBuilt</th><th>SalePrice</th></tr></thead><tbody><tr><td>1</td><td>CollgCr</td><td>1710</td><td>7</td><td>2003</td><td>208500.0</td></tr><tr><td>2</td><td>Veenker</td><td>1262</td><td>6</td><td>1976</td><td>181500.0</td></tr><tr><td>3</td><td>CollgCr</td><td>1786</td><td>7</td><td>2001</td><td>223500.0</td></tr><tr><td>4</td><td>Crawfor</td><td>1717</td><td>7</td><td>1915</td><td>140000.0</td></tr><tr><td>5</td><td>NoRidge</td><td>2198</td><td>8</td><td>2000</td><td>250000.0</td></tr><tr><td>6</td><td>Mitchel</td><td>1362</td><td>5</td><td>1993</td><td>143000.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "CollgCr",
         1710,
         7,
         2003,
         208500.0
        ],
        [
         2,
         "Veenker",
         1262,
         6,
         1976,
         181500.0
        ],
        [
         3,
         "CollgCr",
         1786,
         7,
         2001,
         223500.0
        ],
        [
         4,
         "Crawfor",
         1717,
         7,
         1915,
         140000.0
        ],
        [
         5,
         "NoRidge",
         2198,
         8,
         2000,
         250000.0
        ],
        [
         6,
         "Mitchel",
         1362,
         5,
         1993,
         143000.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Neighborhood",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "GrLivArea",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "OverallQual",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "YearBuilt",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "SalePrice",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- SCHRITT 1: DATEN VORBEREITEN ---\n",
    "# Wir erstellen einen kleinen Datensatz (Ames Housing Dataset Auszug)\n",
    "\n",
    "table_name = \"workspace.default.house_prices\"\n",
    "\n",
    "print(f\"\uD83D\uDD27 Erstelle Trainingstabelle {table_name}...\")\n",
    "\n",
    "data = [\n",
    "    (1, \"CollgCr\", 1710, 7, 2003, 208500.0),\n",
    "    (2, \"Veenker\", 1262, 6, 1976, 181500.0),\n",
    "    (3, \"CollgCr\", 1786, 7, 2001, 223500.0),\n",
    "    (4, \"Crawfor\", 1717, 7, 1915, 140000.0),\n",
    "    (5, \"NoRidge\", 2198, 8, 2000, 250000.0),\n",
    "    (6, \"Mitchel\", 1362, 5, 1993, 143000.0)\n",
    "]\n",
    "\n",
    "columns = [\"Id\", \"Neighborhood\", \"GrLivArea\", \"OverallQual\", \"YearBuilt\", \"SalePrice\"]\n",
    "\n",
    "# Overwrite sorgt dafür, dass wir das Notebook mehrfach starten können\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(\"✅ Daten bereitgestellt.\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2ea1b9-4c54-4937-b8bd-d5cc13c1914d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 Starte Training in Experiment: /Users/philippe.christen@fhnw.ch/House_Price_Predictor\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/26 10:43:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n2025/11/26 10:43:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n\uD83D\uDCCC MERKE DIR DIESES MAPPING FÜR SPÄTER:\n{'CollgCr': np.int64(0), 'Crawfor': np.int64(1), 'Mitchel': np.int64(2), 'NoRidge': np.int64(3), 'Veenker': np.int64(4)}\n------------------------------\n✅ Training beendet! Run ID: 4a55a2947da94c7d994681315ca9b4bc\n"
     ]
    }
   ],
   "source": [
    "# --- SCHRITT 2: TRAINING (DAS LABOR) ---\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Daten laden\n",
    "df_spark = spark.table(table_name)\n",
    "dataset = df_spark.toPandas()\n",
    "\n",
    "# TRICK: Da wir nur 6 Zeilen haben, vervielfachen wir die Daten künstlich (20x),\n",
    "# damit der Algorithmus genug \"Futter\" für den Train/Test-Split hat.\n",
    "dataset = pd.concat([dataset] * 20, ignore_index=True)\n",
    "\n",
    "# 2. Encoding (Text -> Zahl)\n",
    "# Computer können nicht mit \"CollgCr\" rechnen, nur mit Zahlen (0, 1, 2...)\n",
    "le_neighborhood = LabelEncoder()\n",
    "dataset['Neighborhood_encoded'] = le_neighborhood.fit_transform(dataset['Neighborhood'])\n",
    "\n",
    "# Features (X) & Target (y)\n",
    "X = dataset[['Neighborhood_encoded', 'GrLivArea', 'OverallQual', 'YearBuilt']]\n",
    "y = dataset['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. MLflow Setup (Sicherer User-Abruf für Free Edition)\n",
    "username = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "experiment_path = f\"/Users/{username}/House_Price_Predictor\"\n",
    "\n",
    "mlflow.set_experiment(experiment_path)\n",
    "mlflow.sklearn.autolog() # <--- Die Magie: Loggt automatisch Params & Metriken\n",
    "\n",
    "print(f\"\uD83D\uDE80 Starte Training in Experiment: {experiment_path}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"House_Price_Regressor_v1\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # WICHTIG: Das Mapping speichern, damit wir später wissen, was 0, 1, 2 bedeutet!\n",
    "    mapping = dict(zip(le_neighborhood.classes_, le_neighborhood.transform(le_neighborhood.classes_)))\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\uD83D\uDCCC MERKE DIR DIESES MAPPING FÜR SPÄTER:\")\n",
    "    print(mapping)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(f\"✅ Training beendet! Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78b701da-fb77-41b4-82f3-312d6a6f0ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0E Suche neuesten Run im Experiment...\n\uD83D\uDCDD Registriere Modell aus Run 4a55a2947da94c7d994681315ca9b4bc als 'workspace.default.house_price_estimator'...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.house_price_estimator' already exists. Creating a new version of this model...\nCreated version '2' of model 'workspace.default.house_price_estimator'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Warte auf Modell-Bereitstellung........\n✅ Modell ist registriert und bereit!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    }
   ],
   "source": [
    "# --- SCHRITT 3: REGISTRIERUNG (DER TRESOR) ---\n",
    "# Wir automatisieren den Schritt \"Register Model\", den man sonst klickt.\n",
    "\n",
    "import time\n",
    "\n",
    "model_name = \"workspace.default.house_price_estimator\"\n",
    "print(f\"\uD83D\uDD0E Suche neuesten Run im Experiment...\")\n",
    "\n",
    "# Neuesten Run holen\n",
    "current_experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "runs = mlflow.search_runs(experiment_ids=[current_experiment.experiment_id], \n",
    "                          order_by=[\"start_time DESC\"], \n",
    "                          max_results=1)\n",
    "\n",
    "if len(runs) > 0:\n",
    "    latest_run_id = runs.iloc[0][\"run_id\"]\n",
    "    print(f\"\uD83D\uDCDD Registriere Modell aus Run {latest_run_id} als '{model_name}'...\")\n",
    "    \n",
    "    model_uri = f\"runs:/{latest_run_id}/model\"\n",
    "    mlflow.register_model(model_uri, model_name)\n",
    "    \n",
    "    print(\"⏳ Warte auf Modell-Bereitstellung...\", end=\"\")\n",
    "    for _ in range(5):\n",
    "        time.sleep(1)\n",
    "        print(\".\", end=\"\")\n",
    "    print(\"\\n✅ Modell ist registriert und bereit!\")\n",
    "else:\n",
    "    print(\"❌ Fehler: Kein Training gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fd9b05e-dbef-40d7-b2bf-b4c5e8c601b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0E Lade neueste Version von 'workspace.default.house_price_estimator'...\n\n\uD83C\uDFE0 HAUS-ANALYSE:\n   Lage-Code: 2\n   Größe:     2200 sqft\n   Baujahr:   2015\n\uD83D\uDCB0 KI-SCHÄTZUNG: $241,540.00\n"
     ]
    }
   ],
   "source": [
    "# --- SCHRITT 4: VORHERSAGE (DIE ANWENDUNG) ---\n",
    "# Jetzt nutzen wir das Modell wie eine App.\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "print(f\"\uD83D\uDD0E Lade neueste Version von '{model_name}'...\")\n",
    "\n",
    "# Neueste Version finden (Unity Catalog kompatibel)\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "versions.sort(key=lambda x: int(x.version), reverse=True)\n",
    "latest_version = versions[0].version\n",
    "\n",
    "# Modell laden\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{model_name}/{latest_version}\")\n",
    "\n",
    "# --- SZENARIO: Ein neues Haus kommt auf den Markt ---\n",
    "# Neighborhood Code: Siehe Mapping oben! (z.B. 0 = CollgCr, 2 = NoRidge)\n",
    "neue_haus_daten = pd.DataFrame({\n",
    "    \"Neighborhood_encoded\": [2],      # 2 = NoRidge (Teure Gegend!)\n",
    "    \"GrLivArea\":            [2200],   # Großes Haus\n",
    "    \"OverallQual\":          [8],      # Hohe Qualität\n",
    "    \"YearBuilt\":            [2015]    # Modern\n",
    "})\n",
    "\n",
    "# Vorhersage\n",
    "schätzung = loaded_model.predict(neue_haus_daten)[0]\n",
    "\n",
    "print(f\"\\n\uD83C\uDFE0 HAUS-ANALYSE:\")\n",
    "print(f\"   Lage-Code: {neue_haus_daten['Neighborhood_encoded'][0]}\")\n",
    "print(f\"   Größe:     {neue_haus_daten['GrLivArea'][0]} sqft\")\n",
    "print(f\"   Baujahr:   {neue_haus_daten['YearBuilt'][0]}\")\n",
    "print(f\"\uD83D\uDCB0 KI-SCHÄTZUNG: ${schätzung:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed1bd6ba-e927-4fdf-a4c2-e8fda2462541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa6c1ab-7952-492b-9cf8-2c31535de7c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Cleanup übersprungen.\n   Setze die Variable CLEANUP_NOW = True im Code oben, um aufzuräumen.\n"
     ]
    }
   ],
   "source": [
    "# --- CLEANUP SCRIPT ---\n",
    "# Löscht alle Artefakte (Modell, Experiment, Tabelle).\n",
    "\n",
    "# ⚠️ SICHERHEITSSCHALTER: Setze dies auf True, um wirklich zu löschen!\n",
    "CLEANUP_NOW = False \n",
    "\n",
    "if CLEANUP_NOW:\n",
    "    import mlflow\n",
    "    from mlflow import MlflowClient\n",
    "\n",
    "    # 1. Konfiguration\n",
    "    model_name = \"workspace.default.house_price_estimator\"\n",
    "    table_name = \"workspace.default.house_prices\"\n",
    "    \n",
    "    # Username sicher abrufen\n",
    "    username = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "    experiment_name = f\"/Users/{username}/House_Price_Predictor\"\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    print(\"\uD83E\uDDF9 Starte Aufräumen der ML-Umgebung...\")\n",
    "\n",
    "    # --- SCHRITT 1: Modell entfernen ---\n",
    "    try:\n",
    "        print(f\"1️⃣ Prüfe Modell '{model_name}'...\")\n",
    "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if versions:\n",
    "            for v in versions:\n",
    "                client.delete_model_version(name=model_name, version=v.version)\n",
    "            client.delete_registered_model(name=model_name)\n",
    "            print(\"   ✅ Modell komplett gelöscht.\")\n",
    "        else:\n",
    "            print(\"   ℹ️ Modell war schon gelöscht.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Warnung (Modell): {e}\")\n",
    "\n",
    "    # --- SCHRITT 2: Experiment löschen ---\n",
    "    try:\n",
    "        print(f\"2️⃣ Lösche Experiment '{experiment_name}'...\")\n",
    "        experiment = client.get_experiment_by_name(experiment_name)\n",
    "        if experiment:\n",
    "            client.delete_experiment(experiment.experiment_id)\n",
    "            print(\"   ✅ Experiment gelöscht.\")\n",
    "        else:\n",
    "            print(\"   ℹ️ Experiment war schon gelöscht.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Warnung (Experiment): {e}\")\n",
    "\n",
    "    # --- SCHRITT 3: Tabelle löschen ---\n",
    "    # Ich habe die Kommentare entfernt, damit wirklich aufgeräumt wird\n",
    "    print(f\"3️⃣ Lösche Tabelle '{table_name}'...\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "    print(\"   ✅ Tabelle gelöscht.\")\n",
    "\n",
    "    print(\"\\n\uD83C\uDFC1 System ist wieder sauber!\")\n",
    "\n",
    "else:\n",
    "    print(\"ℹ️ Cleanup übersprungen.\")\n",
    "    print(\"   Setze die Variable CLEANUP_NOW = True im Code oben, um aufzuräumen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c5ccbd-9d6a-4489-aee6-01611712cf57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "67_AI_ML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}